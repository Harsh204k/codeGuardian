# ğŸ¨ Pipeline Architecture Diagram

## ğŸ“Š Data Flow Visualization

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INPUT: Raw Preprocessed Datasets                      â”‚
â”‚                                                                           â”‚
â”‚  devign/processed/raw_cleaned.jsonl                                      â”‚
â”‚  diversevul/processed/raw_cleaned.jsonl                                  â”‚
â”‚  juliet/processed/raw_cleaned.jsonl                                      â”‚
â”‚  zenodo/processed/raw_cleaned.jsonl                                      â”‚
â”‚  codexglue_defect/processed/raw_cleaned.jsonl                            â”‚
â”‚  [megavul/processed/raw_cleaned.jsonl] â† Future                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1: NORMALIZATION                                 â”‚
â”‚                                                                           â”‚
â”‚  For each dataset:                                                        â”‚
â”‚    1. Load JSONL (streaming, line-by-line)                               â”‚
â”‚    2. Extract fields with fallbacks                                      â”‚
â”‚    3. Normalize language names (C, C++, Java, etc.)                      â”‚
â”‚    4. Normalize CWE/CVE IDs (CWE-XXX, CVE-YYYY-XXXXX)                    â”‚
â”‚    5. Auto-fill missing CWE from description                             â”‚
â”‚    6. Derive attack type from CWE (50+ mappings)                         â”‚
â”‚    7. Auto-score severity (low/medium/high/critical)                     â”‚
â”‚    8. Compute SHA-256 code hash                                          â”‚
â”‚    9. Count function length                                              â”‚
â”‚   10. Extract imports (language-specific)                                â”‚
â”‚   11. Generate UUID, timestamps                                          â”‚
â”‚   12. Sanitize UTF-8 encoding                                            â”‚
â”‚   13. Validate required fields                                           â”‚
â”‚   14. Save normalized output                                             â”‚
â”‚                                                                           â”‚
â”‚  Output per dataset:                                                      â”‚
â”‚    â†’ datasets/<dataset>/normalized/normalized.jsonl                      â”‚
â”‚    â†’ datasets/<dataset>/normalized/stats.json                            â”‚
â”‚    â†’ logs/normalization/<dataset>.log                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PHASE 2: DEDUPLICATION (Optional: --deduplicate)             â”‚
â”‚                                                                           â”‚
â”‚  1. Collect all normalized records                                        â”‚
â”‚  2. Group by code_hash (SHA-256)                                         â”‚
â”‚  3. Keep first occurrence per hash                                       â”‚
â”‚  4. Track duplicates removed per dataset                                 â”‚
â”‚  5. Log deduplication statistics                                         â”‚
â”‚                                                                           â”‚
â”‚  Example results:                                                         â”‚
â”‚    Before: 1,108,214 records                                             â”‚
â”‚    After:  1,095,437 records                                             â”‚
â”‚    Removed: 12,777 duplicates                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                PHASE 3: MERGING & STATISTICS                              â”‚
â”‚                                                                           â”‚
â”‚  1. Merge all normalized datasets                                         â”‚
â”‚  2. Generate overall statistics:                                          â”‚
â”‚     â€¢ Total records, vulnerability ratio                                 â”‚
â”‚     â€¢ Language distribution                                              â”‚
â”‚     â€¢ CWE/CVE coverage                                                   â”‚
â”‚     â€¢ Severity distribution                                              â”‚
â”‚     â€¢ Attack type distribution                                           â”‚
â”‚     â€¢ Project distribution                                               â”‚
â”‚                                                                           â”‚
â”‚  3. Create output artifacts:                                              â”‚
â”‚     â€¢ final_merged_dataset.jsonl                                         â”‚
â”‚     â€¢ merged_stats.json                                                  â”‚
â”‚     â€¢ stats_summary.csv                                                  â”‚
â”‚     â€¢ combined_report.md (Markdown)                                      â”‚
â”‚     â€¢ schema.json (Documentation)                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         OUTPUT: Unified Dataset                           â”‚
â”‚                                                                           â”‚
â”‚  datasets/combined/                                                       â”‚
â”‚  â”œâ”€â”€ final_merged_dataset.jsonl  â† â­ Main unified dataset               â”‚
â”‚  â”œâ”€â”€ merged_stats.json            â† Overall statistics                   â”‚
â”‚  â”œâ”€â”€ stats_summary.csv            â† Per-dataset CSV                      â”‚
â”‚  â”œâ”€â”€ combined_report.md           â† Markdown audit report                â”‚
â”‚  â””â”€â”€ schema.json                  â† Schema documentation                 â”‚
â”‚                                                                           â”‚
â”‚  Ready for:                                                               â”‚
â”‚  âœ… Feature Engineering (M1-M15)                                          â”‚
â”‚  âœ… Static Analysis Integration                                           â”‚
â”‚  âœ… ML Model Training                                                     â”‚
â”‚  âœ… LLM Fine-tuning                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Record Transformation Flow

```
INPUT RECORD (raw_cleaned.jsonl)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {                              â”‚
â”‚   "func": "void foo() {...}",  â”‚
â”‚   "target": 1,                 â”‚
â”‚   "project": "linux",          â”‚
â”‚   "commit_id": "abc123",       â”‚
â”‚   "cwe": "79"                  â”‚
â”‚ }                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
      NORMALIZATION
             â”‚
             â–¼
OUTPUT RECORD (normalized.jsonl)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ {                                                      â”‚
â”‚   "id": "550e8400-e29b-41d4-a716-446655440000",       â”‚
â”‚   "language": "C",                                     â”‚
â”‚   "dataset": "devign",                                 â”‚
â”‚   "source": null,                                      â”‚
â”‚   "code": "void foo() {...}",                          â”‚
â”‚   "is_vulnerable": 1,                                  â”‚
â”‚   "attack_type": "Cross-Site Scripting (XSS)",         â”‚
â”‚   "severity": "medium",                                â”‚
â”‚   "cwe_id": "CWE-79",                                  â”‚
â”‚   "cve_id": null,                                      â”‚
â”‚   "description": null,                                 â”‚
â”‚   "fix_available": null,                               â”‚
â”‚   "patch_commit": null,                                â”‚
â”‚   "project": "linux",                                  â”‚
â”‚   "file_name": null,                                   â”‚
â”‚   "method_name": "foo",                                â”‚
â”‚   "commit_id": "abc123",                               â”‚
â”‚   "line_range": null,                                  â”‚
â”‚   "code_hash": "d3f5a9b2...",                          â”‚
â”‚   "metrics": null,                                     â”‚
â”‚   "function_length": 15,                               â”‚
â”‚   "imports_used": ["stdio.h", "stdlib.h"],            â”‚
â”‚   "dependencies": null,                                â”‚
â”‚   "taint_flows": null,                                 â”‚
â”‚   "record_created": "2025-10-11T14:35:22.123456+00:00",â”‚
â”‚   "record_updated": "2025-10-11T14:35:22.123456+00:00",â”‚
â”‚   "processing_stage": "normalized",                    â”‚
â”‚   "review_status": "auto_verified"                     â”‚
â”‚ }                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ CWE Intelligence System

```
CWE-89 â”€â”€â”¬â”€â†’ Attack Type: "SQL Injection"
         â””â”€â†’ Severity: "high"

CWE-119 â”€â”¬â”€â†’ Attack Type: "Buffer Overflow"
         â””â”€â†’ Severity: "critical"

CWE-79 â”€â”€â”¬â”€â†’ Attack Type: "Cross-Site Scripting (XSS)"
         â””â”€â†’ Severity: "medium"

CWE-787 â”€â”¬â”€â†’ Attack Type: "Out-of-bounds Write"
         â””â”€â†’ Severity: "critical"

CWE-416 â”€â”¬â”€â†’ Attack Type: "Use After Free"
         â””â”€â†’ Severity: "critical"

... and 45+ more mappings
```

## ğŸ“Š Statistics Generation

```
Per-Dataset Stats                    Overall Stats
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ devign              â”‚             â”‚ Total: 1,095,437        â”‚
â”‚ â”œâ”€ Total: 27,318    â”‚             â”‚ Vulnerable: 111,234     â”‚
â”‚ â”œâ”€ Vuln: 2,732      â”‚             â”‚ Languages: 12           â”‚
â”‚ â”œâ”€ Langs: 2         â”‚â”€â”€â”€â”€â”€â”€â”€â”     â”‚ CWEs: 267               â”‚
â”‚ â””â”€ CWEs: 45         â”‚       â”‚     â”‚ Projects: 1,523         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚ diversevul          â”‚       â”‚
â”‚ â”œâ”€ Total: 826,318   â”‚       â”‚
â”‚ â”œâ”€ Vuln: 82,632     â”‚       â”‚
â”‚ â”œâ”€ Langs: 8         â”‚â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â†’ MERGE â”€â”€â†’ merged_stats.json
â”‚ â””â”€ CWEs: 178        â”‚       â”‚              stats_summary.csv
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚              combined_report.md
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚ juliet              â”‚       â”‚
â”‚ â”œâ”€ Total: 152,674   â”‚       â”‚
â”‚ â”œâ”€ Vuln: 15,267     â”‚       â”‚
â”‚ â”œâ”€ Langs: 3         â”‚â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â””â”€ CWEs: 118        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ CLI Command Flow

```
User Command:
  python normalize_and_merge_all.py --datasets devign diversevul --deduplicate

                â”‚
                â–¼
         Parse Arguments
                â”‚
                â–¼
         Setup Directories
                â”‚
                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  For each dataset:     â”‚
    â”‚  1. Load & Normalize   â”‚
    â”‚  2. Save normalized    â”‚
    â”‚  3. Generate stats     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
       Collect All Records
                â”‚
                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Deduplication:        â”‚
    â”‚  1. Group by hash      â”‚
    â”‚  2. Remove duplicates  â”‚
    â”‚  3. Track stats        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Merge & Stats:        â”‚
    â”‚  1. Merge all records  â”‚
    â”‚  2. Generate stats     â”‚
    â”‚  3. Create reports     â”‚
    â”‚  4. Save outputs       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
         Print Summary
                â”‚
                â–¼
              Done! âœ…
```

## ğŸ§  Enrichment Pipeline

```
Raw Code
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Normalization              â”‚
â”‚  â€¢ Remove extra whitespace  â”‚
â”‚  â€¢ Standardize formatting   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Hashing                    â”‚
â”‚  â€¢ Normalize (strip, lower) â”‚
â”‚  â€¢ Compute SHA-256          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Metrics Extraction         â”‚
â”‚  â€¢ Count lines              â”‚
â”‚  â€¢ Extract imports          â”‚
â”‚  â€¢ Detect language features â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CWE Intelligence           â”‚
â”‚  â€¢ Map to attack type       â”‚
â”‚  â€¢ Assign severity          â”‚
â”‚  â€¢ Extract from description â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Metadata Addition          â”‚
â”‚  â€¢ Generate UUID            â”‚
â”‚  â€¢ Add timestamps           â”‚
â”‚  â€¢ Set processing stage     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    Enriched Record
```

## ğŸ“ˆ Quality Metrics

```
Validation Checks:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ âœ… Required Fields Present          â”‚
â”‚    â€¢ id, code, label, language      â”‚
â”‚    â€¢ dataset                        â”‚
â”‚                                     â”‚
â”‚ âœ… Data Type Validation             â”‚
â”‚    â€¢ is_vulnerable: int (0 or 1)    â”‚
â”‚    â€¢ language: string               â”‚
â”‚    â€¢ code: non-empty string         â”‚
â”‚                                     â”‚
â”‚ âœ… Format Validation                â”‚
â”‚    â€¢ CWE-XXX pattern                â”‚
â”‚    â€¢ CVE-YYYY-XXXXX pattern         â”‚
â”‚    â€¢ UUID format                    â”‚
â”‚    â€¢ ISO timestamp format           â”‚
â”‚                                     â”‚
â”‚ âœ… Encoding Validation              â”‚
â”‚    â€¢ Valid UTF-8                    â”‚
â”‚    â€¢ No null bytes                  â”‚
â”‚    â€¢ Sanitized characters           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

**This diagram illustrates the complete end-to-end pipeline architecture!** ğŸš€
