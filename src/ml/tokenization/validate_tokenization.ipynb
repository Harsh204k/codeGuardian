{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09934bad",
   "metadata": {},
   "source": [
    "# üîç CodeGuardian Tokenization Validation Notebook\n",
    "\n",
    "**Author:** Urva Gandhi  \n",
    "**Purpose:** Validate tokenized outputs match original dataset splits\n",
    "\n",
    "This notebook verifies:\n",
    "1. ‚úÖ Row counts match exactly between JSONL and tokenized .pt files\n",
    "2. ‚úÖ Label distributions are preserved\n",
    "3. ‚úÖ No data loss during tokenization\n",
    "4. ‚úÖ Both CodeBERT and GraphCodeBERT outputs are consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbdd18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import os\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üöÄ CodeGuardian Tokenization Validation\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10b723",
   "metadata": {},
   "source": [
    "## üìÅ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9dd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "JSONL_DIR = \"/kaggle/input/codeguardian-dataset-for-model-fine-tuning/random_splitted\"\n",
    "TOKENIZED_BASE = \"/kaggle/working/tokenized\"\n",
    "\n",
    "# Splits to check\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Models\n",
    "MODELS = [\"codebert\", \"graphcodebert\"]\n",
    "\n",
    "print(f\"JSONL Directory: {JSONL_DIR}\")\n",
    "print(f\"Tokenized Base: {TOKENIZED_BASE}\")\n",
    "print(f\"Splits: {SPLITS}\")\n",
    "print(f\"Models: {MODELS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f289b",
   "metadata": {},
   "source": [
    "## üìä Step 1: Count Original JSONL Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_jsonl_samples(file_path):\n",
    "    \"\"\"Count samples and label distribution in JSONL file\"\"\"\n",
    "    total = 0\n",
    "    labels = []\n",
    "    valid = 0\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                code = item.get(\"code\", \"\")\n",
    "                label = item.get(\"is_vulnerable\", None)\n",
    "\n",
    "                # Apply same validation logic as tokenizer\n",
    "                if isinstance(code, str) and code.strip() != \"\" and label is not None:\n",
    "                    label_int = int(label)\n",
    "                    if label_int in [0, 1]:\n",
    "                        labels.append(label_int)\n",
    "                        valid += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    label_counts = Counter(labels)\n",
    "    return total, valid, label_counts\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ORIGINAL JSONL STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "jsonl_stats = {}\n",
    "for split in SPLITS:\n",
    "    file_path = os.path.join(JSONL_DIR, f\"{split}.jsonl\")\n",
    "    total, valid, label_counts = count_jsonl_samples(file_path)\n",
    "    jsonl_stats[split] = {\n",
    "        \"total\": total,\n",
    "        \"valid\": valid,\n",
    "        \"labels\": label_counts\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    print(f\"  Total lines: {total:,}\")\n",
    "    print(f\"  Valid samples: {valid:,}\")\n",
    "    print(f\"  Skipped: {total - valid:,}\")\n",
    "    print(f\"  Label 0 (Secure): {label_counts[0]:,} ({100*label_counts[0]/valid:.2f}%)\")\n",
    "    print(f\"  Label 1 (Vulnerable): {label_counts[1]:,} ({100*label_counts[1]/valid:.2f}%)\")\n",
    "\n",
    "total_valid = sum(s[\"valid\"] for s in jsonl_stats.values())\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"TOTAL VALID SAMPLES: {total_valid:,}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753faa2",
   "metadata": {},
   "source": [
    "## üì¶ Step 2: Validate CodeBERT Tokenized Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_tokenized_file(file_path, expected_count, expected_labels):\n",
    "    \"\"\"Validate a tokenized .pt file\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return False, \"File not found\", {}\n",
    "\n",
    "    try:\n",
    "        data = torch.load(file_path, map_location=\"cpu\")\n",
    "\n",
    "        # Check keys\n",
    "        required_keys = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
    "        if not all(k in data for k in required_keys):\n",
    "            return False, \"Missing required keys\", {}\n",
    "\n",
    "        # Check counts\n",
    "        actual_count = len(data[\"labels\"])\n",
    "        if actual_count != expected_count:\n",
    "            return False, f\"Count mismatch: expected {expected_count}, got {actual_count}\", {}\n",
    "\n",
    "        # Check label distribution\n",
    "        labels = data[\"labels\"].tolist()\n",
    "        label_counts = Counter(labels)\n",
    "\n",
    "        if label_counts != expected_labels:\n",
    "            return False, f\"Label mismatch\", label_counts\n",
    "\n",
    "        # Check shapes\n",
    "        input_shape = data[\"input_ids\"].shape\n",
    "        mask_shape = data[\"attention_mask\"].shape\n",
    "\n",
    "        if input_shape[1] != 512 or mask_shape[1] != 512:\n",
    "            return False, \"Incorrect sequence length\", label_counts\n",
    "\n",
    "        return True, \"Valid\", label_counts\n",
    "\n",
    "    except Exception as e:\n",
    "        return False, f\"Load error: {str(e)}\", {}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CODEBERT TOKENIZED VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "codebert_valid = True\n",
    "for split in SPLITS:\n",
    "    file_path = os.path.join(TOKENIZED_BASE, \"codebert\", f\"{split}_tokenized.pt\")\n",
    "    expected_count = jsonl_stats[split][\"valid\"]\n",
    "    expected_labels = jsonl_stats[split][\"labels\"]\n",
    "\n",
    "    valid, message, actual_labels = validate_tokenized_file(file_path, expected_count, expected_labels)\n",
    "\n",
    "    print(f\"\\n{split.upper()}: {'‚úÖ' if valid else '‚ùå'} {message}\")\n",
    "    if valid:\n",
    "        print(f\"  Samples: {expected_count:,}\")\n",
    "        print(f\"  Label 0: {actual_labels[0]:,}\")\n",
    "        print(f\"  Label 1: {actual_labels[1]:,}\")\n",
    "    else:\n",
    "        codebert_valid = False\n",
    "        if actual_labels:\n",
    "            print(f\"  Expected: {expected_labels}\")\n",
    "            print(f\"  Actual: {actual_labels}\")\n",
    "\n",
    "if codebert_valid:\n",
    "    print(\"\\n‚úÖ CodeBERT tokenization: PASSED\")\n",
    "else:\n",
    "    print(\"\\n‚ùå CodeBERT tokenization: FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7af1256",
   "metadata": {},
   "source": [
    "## üì¶ Step 3: Validate GraphCodeBERT Tokenized Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c6895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GRAPHCODEBERT TOKENIZED VALIDATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "graphcodebert_valid = True\n",
    "for split in SPLITS:\n",
    "    file_path = os.path.join(TOKENIZED_BASE, \"graphcodebert\", f\"{split}_tokenized.pt\")\n",
    "    expected_count = jsonl_stats[split][\"valid\"]\n",
    "    expected_labels = jsonl_stats[split][\"labels\"]\n",
    "\n",
    "    valid, message, actual_labels = validate_tokenized_file(file_path, expected_count, expected_labels)\n",
    "\n",
    "    print(f\"\\n{split.upper()}: {'‚úÖ' if valid else '‚ùå'} {message}\")\n",
    "    if valid:\n",
    "        print(f\"  Samples: {expected_count:,}\")\n",
    "        print(f\"  Label 0: {actual_labels[0]:,}\")\n",
    "        print(f\"  Label 1: {actual_labels[1]:,}\")\n",
    "    else:\n",
    "        graphcodebert_valid = False\n",
    "        if actual_labels:\n",
    "            print(f\"  Expected: {expected_labels}\")\n",
    "            print(f\"  Actual: {actual_labels}\")\n",
    "\n",
    "if graphcodebert_valid:\n",
    "    print(\"\\n‚úÖ GraphCodeBERT tokenization: PASSED\")\n",
    "else:\n",
    "    print(\"\\n‚ùå GraphCodeBERT tokenization: FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf9a8d4",
   "metadata": {},
   "source": [
    "## üîç Step 4: Cross-Model Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5cfb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CROSS-MODEL CONSISTENCY CHECK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "consistency_check = True\n",
    "\n",
    "for split in SPLITS:\n",
    "    codebert_path = os.path.join(TOKENIZED_BASE, \"codebert\", f\"{split}_tokenized.pt\")\n",
    "    graphcodebert_path = os.path.join(TOKENIZED_BASE, \"graphcodebert\", f\"{split}_tokenized.pt\")\n",
    "\n",
    "    try:\n",
    "        codebert_data = torch.load(codebert_path, map_location=\"cpu\")\n",
    "        graphcodebert_data = torch.load(graphcodebert_path, map_location=\"cpu\")\n",
    "\n",
    "        # Check sample counts\n",
    "        cb_count = len(codebert_data[\"labels\"])\n",
    "        gcb_count = len(graphcodebert_data[\"labels\"])\n",
    "\n",
    "        # Check label distributions\n",
    "        cb_labels = Counter(codebert_data[\"labels\"].tolist())\n",
    "        gcb_labels = Counter(graphcodebert_data[\"labels\"].tolist())\n",
    "\n",
    "        if cb_count == gcb_count and cb_labels == gcb_labels:\n",
    "            print(f\"\\n{split.upper()}: ‚úÖ Consistent\")\n",
    "            print(f\"  Both models: {cb_count:,} samples\")\n",
    "            print(f\"  Both models: Label 0={cb_labels[0]:,}, Label 1={cb_labels[1]:,}\")\n",
    "        else:\n",
    "            print(f\"\\n{split.upper()}: ‚ùå Inconsistent\")\n",
    "            print(f\"  CodeBERT: {cb_count:,} samples, {cb_labels}\")\n",
    "            print(f\"  GraphCodeBERT: {gcb_count:,} samples, {gcb_labels}\")\n",
    "            consistency_check = False\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{split.upper()}: ‚ùå Error - {str(e)}\")\n",
    "        consistency_check = False\n",
    "\n",
    "if consistency_check:\n",
    "    print(\"\\n‚úÖ Cross-model consistency: PASSED\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Cross-model consistency: FAILED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf8286",
   "metadata": {},
   "source": [
    "## üìà Step 5: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL VALIDATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_checks = [\n",
    "    (\"CodeBERT Tokenization\", codebert_valid),\n",
    "    (\"GraphCodeBERT Tokenization\", graphcodebert_valid),\n",
    "    (\"Cross-Model Consistency\", consistency_check)\n",
    "]\n",
    "\n",
    "print(\"\\nüìä Validation Results:\")\n",
    "for check_name, passed in all_checks:\n",
    "    status = \"‚úÖ PASSED\" if passed else \"‚ùå FAILED\"\n",
    "    print(f\"  {check_name}: {status}\")\n",
    "\n",
    "all_passed = all(passed for _, passed in all_checks)\n",
    "\n",
    "if all_passed:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"üéâ ALL VALIDATION CHECKS PASSED!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n‚úÖ Tokenized datasets are ready for training\")\n",
    "    print(\"‚úÖ No data loss detected\")\n",
    "    print(\"‚úÖ Label distributions preserved\")\n",
    "    print(\"‚úÖ Both models have consistent outputs\")\n",
    "    print(\"\\nüí° Next Steps:\")\n",
    "    print(\"  1. Proceed with LoRA fine-tuning\")\n",
    "    print(\"  2. Run train_codebert_lora.py\")\n",
    "    print(\"  3. Run train_graphcodebert_lora.py\")\n",
    "    print(\"  4. Create hybrid ensemble model\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"‚ö†Ô∏è VALIDATION FAILED\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"\\n‚ùå Please review the errors above and re-run tokenization\")\n",
    "    print(\"\\nüí° Troubleshooting:\")\n",
    "    print(\"  1. Check if tokenization scripts completed successfully\")\n",
    "    print(\"  2. Verify JSONL files are not corrupted\")\n",
    "    print(\"  3. Ensure sufficient disk space\")\n",
    "    print(\"  4. Re-run tokenization scripts if needed\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eb4382",
   "metadata": {},
   "source": [
    "## üìä Bonus: Sample Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d4d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first 5 samples from train set to inspect\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SAMPLE INSPECTION (First 5 train samples)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "train_codebert = torch.load(\n",
    "    os.path.join(TOKENIZED_BASE, \"codebert\", \"train_tokenized.pt\"),\n",
    "    map_location=\"cpu\"\n",
    ")\n",
    "\n",
    "print(\"\\nCodeBERT Samples:\")\n",
    "for i in range(min(5, len(train_codebert[\"labels\"]))):\n",
    "    label = train_codebert[\"labels\"][i].item()\n",
    "    num_tokens = train_codebert[\"attention_mask\"][i].sum().item()\n",
    "    print(f\"  Sample {i+1}: Label={label}, Active Tokens={num_tokens}/512\")\n",
    "\n",
    "print(\"\\n‚úÖ Validation notebook completed!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
