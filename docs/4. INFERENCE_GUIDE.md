# ðŸš€ XGBoost Models - Inference Guide

**Phase 3.2 - Production ML Pipeline**  
**Date:** October 8, 2025  
**Status:** âœ… COMPLETE

---

## ðŸ“‹ Overview

This guide covers inference using the trained XGBoost models for vulnerability detection:

1. **Static Model Inference** - Using tabular features (M1-M15)
2. **Fusion Model Inference** - Meta-model combining Static + CodeBERT + GraphCodeBERT

Both inference scripts are production-ready with:
- âœ… Automatic model/metadata loading
- âœ… Batch processing support
- âœ… SHAP explainability
- âœ… CWE mapping
- âœ… Consistent JSONL output
- âœ… Error handling and logging

---

## ðŸ”¹ 1. Static Model Inference

### Basic Usage

```bash
python src/static/models/infer_xgboost_static.py \
    --model-path models/static/xgb_static_v20231008_143022.joblib \
    --input-path datasets/features/test_features.csv \
    --output-path outputs/inference/static_results.jsonl
```

### With Explainability

```bash
python src/static/models/infer_xgboost_static.py \
    --model-path models/static/xgb_static_v20231008_143022.joblib \
    --input-path datasets/features/test_features.csv \
    --output-path outputs/inference/static_results.jsonl \
    --explain \
    --config src/static/models/model_config.yml
```

### Batch Processing (Large Datasets)

```bash
python src/static/models/infer_xgboost_static.py \
    --model-path models/static/xgb_static_v20231008_143022.joblib \
    --input-path datasets/features/large_test.csv \
    --output-path outputs/inference/static_results.jsonl \
    --chunk-size 1000 \
    --explain
```

### CLI Arguments

| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `--model-path` | str | **required** | Path to trained model (.joblib) |
| `--input-path` | str | **required** | Path to input data (CSV/JSONL) |
| `--output-path` | str | `outputs/inference/static_results.jsonl` | Output path |
| `--metadata-path` | str | auto-detected | Model metadata YAML |
| `--imputer-path` | str | auto-detected | Fitted imputer |
| `--config` | str | None | model_config.yml path |
| `--format` | str | `auto` | Input format (auto/csv/jsonl) |
| `--explain` | flag | False | Compute SHAP explainability |
| `--chunk-size` | int | None | Process in chunks |
| `--use-calibrated` | flag | True | Use calibrated model |

### Input Format

**CSV Format:**
```csv
id,file,function,M1,M2,M3,...,M15,label
1,app.py,validate_input,0.5,0.3,0.8,...,0.2,1
```

**JSONL Format:**
```json
{"id": 1, "file": "app.py", "function": "validate_input", "M1": 0.5, ..., "label": 1}
```

### Output Format

**`static_results.jsonl`:**
```json
{
  "id": 1,
  "file": "app.py",
  "function": "validate_input",
  "vulnerability_label": 1,
  "vulnerability_probability": 0.87,
  "cwe_hint": "CWE-79",
  "source": "static_analyzer",
  "timestamp": "2023-10-08T14:30:22",
  "true_label": 1
}
```

**`static_results_summary.json`:**
```json
{
  "total_samples": 1000,
  "positive_predictions": 234,
  "negative_predictions": 766,
  "mean_probability": 0.42,
  "positive_rate": 0.234,
  "timestamp": "2023-10-08T14:30:22"
}
```

### Explainability Outputs

When `--explain` is used, additional files are created in `outputs/inference/explainability/`:

1. **`feature_importance.csv`** - XGBoost feature importances
   ```csv
   feature,importance
   M5,0.245
   M12,0.189
   M3,0.156
   ```

2. **`shap_values.csv`** - SHAP values for each sample
3. **`mean_shap_importance.csv`** - Mean absolute SHAP per feature

---

## ðŸ”¹ 2. Fusion Model Inference

### Basic Usage

```bash
python src/ml/fusion/infer_fusion_model.py \
    --model-path models/fusion/xgb_fusion_v20231008_150022.joblib \
    --static-results outputs/inference/static_results.jsonl \
    --codebert-results outputs/inference/codebert_results.jsonl \
    --graphcodebert-results outputs/inference/graphcodebert_results.jsonl \
    --output-path outputs/inference/fusion_results.jsonl
```

### With Explainability

```bash
python src/ml/fusion/infer_fusion_model.py \
    --model-path models/fusion/xgb_fusion_v20231008_150022.joblib \
    --static-results outputs/inference/static_results.jsonl \
    --codebert-results outputs/inference/codebert_results.jsonl \
    --graphcodebert-results outputs/inference/graphcodebert_results.jsonl \
    --output-path outputs/inference/fusion_results.jsonl \
    --explain \
    --config src/ml/fusion/fusion_config.yml
```

### Using LLM Results (Alternative)

```bash
python src/ml/fusion/infer_fusion_model.py \
    --model-path models/fusion/xgb_fusion_v20231008_150022.joblib \
    --static-results outputs/inference/static_results.jsonl \
    --llm-results outputs/inference/llm_results.jsonl \
    --output-path outputs/inference/fusion_results.jsonl \
    --explain
```

### CLI Arguments

| Argument | Type | Default | Description |
|----------|------|---------|-------------|
| `--model-path` | str | **required** | Path to trained fusion model |
| `--static-results` | str | None | Static predictions (JSONL) |
| `--codebert-results` | str | None | CodeBERT predictions (JSONL) |
| `--graphcodebert-results` | str | None | GraphCodeBERT predictions (JSONL) |
| `--llm-results` | str | None | LLM predictions (JSONL) |
| `--output-path` | str | `outputs/inference/fusion_results.jsonl` | Output path |
| `--metadata-path` | str | auto-detected | Model metadata YAML |
| `--imputer-path` | str | auto-detected | Fitted imputer |
| `--config` | str | None | fusion_config.yml path |
| `--explain` | flag | False | Compute SHAP explainability |
| `--use-calibrated` | flag | True | Use calibrated model |

**Note:** Must provide at least one of: `--static-results`, `--codebert-results`, `--graphcodebert-results`, or `--llm-results`

### Input Format Requirements

Each input JSONL file should have predictions with probabilities:

**Static Results:**
```json
{"id": 1, "file": "app.py", "function": "validate", "vulnerability_probability": 0.87, "vulnerability_label": 1}
```

**CodeBERT Results:**
```json
{"id": 1, "file": "app.py", "function": "validate", "vulnerability_probability": 0.92, "vulnerability_label": 1}
```

**GraphCodeBERT Results:**
```json
{"id": 1, "file": "app.py", "function": "validate", "vulnerability_probability": 0.85, "vulnerability_label": 1}
```

### Output Format

**`fusion_results.jsonl`:**
```json
{
  "id": 1,
  "file": "app.py",
  "function": "validate_input",
  "final_vulnerability_label": 1,
  "final_vulnerability_probability": 0.91,
  "selected_cwe_id": "CWE-79",
  "source": "fusion",
  "timestamp": "2023-10-08T15:00:22",
  "true_label": 1
}
```

### Explainability Outputs

When `--explain` is used, additional files in `outputs/inference/explainability/`:

1. **`fusion_feature_importance.csv`** - Fusion model feature importances
2. **`fusion_shap_values.csv`** - SHAP values
3. **`fusion_mean_shap_importance.csv`** - Mean SHAP per feature
4. **`subsystem_contributions.json`** - Contribution analysis

**Subsystem Contributions:**
```json
{
  "static": 0.234,
  "codebert": 0.456,
  "graphcodebert": 0.310
}
```

This shows which subsystem contributes most to fusion predictions.

---

## ðŸ”¹ 3. Integration with Pipeline

### Full Pipeline Example

```bash
# Step 1: Run static inference
python src/static/models/infer_xgboost_static.py \
    --model-path models/static/best_model.joblib \
    --input-path datasets/test/test_features.csv \
    --output-path outputs/static_preds.jsonl

# Step 2: Run CodeBERT inference (from your ML pipeline)
python src/ml/codebert/infer.py \
    --input datasets/test/test_code.jsonl \
    --output outputs/codebert_preds.jsonl

# Step 3: Run GraphCodeBERT inference
python src/ml/graphcodebert/infer.py \
    --input datasets/test/test_code.jsonl \
    --output outputs/graphcodebert_preds.jsonl

# Step 4: Run fusion inference
python src/ml/fusion/infer_fusion_model.py \
    --model-path models/fusion/best_fusion.joblib \
    --static-results outputs/static_preds.jsonl \
    --codebert-results outputs/codebert_preds.jsonl \
    --graphcodebert-results outputs/graphcodebert_preds.jsonl \
    --output-path outputs/final_predictions.jsonl \
    --explain
```

### Integration with `run_pipeline.py`

Update your main pipeline script:

```python
# In run_pipeline.py

def run_inference_phase(args):
    """Run inference using trained models."""
    logger.info("Phase: Inference")
    
    # Static inference
    if args.models in ['static', 'all']:
        logger.info("Running static inference...")
        subprocess.run([
            'python', 'src/static/models/infer_xgboost_static.py',
            '--model-path', args.static_model,
            '--input-path', args.test_features,
            '--output-path', 'outputs/static_results.jsonl',
            '--explain' if args.explain else ''
        ])
    
    # Fusion inference
    if args.models in ['fusion', 'all']:
        logger.info("Running fusion inference...")
        subprocess.run([
            'python', 'src/ml/fusion/infer_fusion_model.py',
            '--model-path', args.fusion_model,
            '--static-results', 'outputs/static_results.jsonl',
            '--codebert-results', args.codebert_results,
            '--graphcodebert-results', args.graphcodebert_results,
            '--output-path', 'outputs/fusion_results.jsonl',
            '--explain' if args.explain else ''
        ])
```

---

## ðŸ”¹ 4. Error Handling

Both scripts include comprehensive error handling:

### Missing Model Files
```
FileNotFoundError: Model not found: models/static/missing_model.joblib
```
**Solution:** Verify model path or train model first

### Missing Features
```
WARNING: Missing features: ['M5', 'M12']. Filling with zeros.
```
**Solution:** Automatically handled - missing features filled with defaults

### Input Format Errors
```
ValueError: Cannot auto-detect format for: test.txt
```
**Solution:** Use `--format csv` or `--format jsonl` explicitly

### Missing Companion Files
```
WARNING: Metadata file not found. Using defaults.
WARNING: Imputer file not found. Skipping imputation.
```
**Solution:** Acceptable - scripts work without metadata/imputer

---

## ðŸ”¹ 5. Performance Tips

### Large Datasets

For datasets > 10,000 samples:

```bash
# Use chunked processing
python src/static/models/infer_xgboost_static.py \
    --model-path models/static/model.joblib \
    --input-path large_dataset.csv \
    --output-path outputs/results.jsonl \
    --chunk-size 5000  # Process 5000 samples at a time
```

### Skip Explainability

For faster inference (especially in production):

```bash
# Omit --explain flag
python src/static/models/infer_xgboost_static.py \
    --model-path models/static/model.joblib \
    --input-path test.csv \
    --output-path outputs/results.jsonl
# No --explain flag = much faster
```

### Parallel Processing

For multiple test files:

```bash
# Process files in parallel using GNU Parallel
parallel -j 4 python src/static/models/infer_xgboost_static.py \
    --model-path models/static/model.joblib \
    --input-path {} \
    --output-path {.}_results.jsonl \
    ::: test_file*.csv
```

---

## ðŸ”¹ 6. Outputs Directory Structure

After inference, your directory structure:

```
outputs/
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ static_results.jsonl          # Static predictions
â”‚   â”œâ”€â”€ static_results_summary.json   # Static summary
â”‚   â”œâ”€â”€ fusion_results.jsonl          # Fusion predictions
â”‚   â”œâ”€â”€ fusion_results_summary.json   # Fusion summary
â”‚   â””â”€â”€ explainability/
â”‚       â”œâ”€â”€ feature_importance.csv
â”‚       â”œâ”€â”€ shap_values.csv
â”‚       â”œâ”€â”€ mean_shap_importance.csv
â”‚       â”œâ”€â”€ fusion_feature_importance.csv
â”‚       â”œâ”€â”€ fusion_shap_values.csv
â”‚       â”œâ”€â”€ fusion_mean_shap_importance.csv
â”‚       â””â”€â”€ subsystem_contributions.json
```

---

## ðŸ”¹ 7. Troubleshooting

### Issue: "Model format not recognized"

**Solution:** Ensure model saved with joblib:
```python
import joblib
joblib.dump(model, 'model.joblib')
```

### Issue: "Feature names mismatch"

**Solution:** Models auto-detect and handle missing features. Check logs for warnings.

### Issue: "Predictions all zeros/ones"

**Possible causes:**
1. Model not trained properly
2. Input features not normalized/scaled
3. Wrong model loaded

**Solution:** Verify model training metrics first

### Issue: "SHAP computation slow"

**Solution:** Reduce `n_samples` in config or code:
```python
# In compute_explainability()
n_samples = 100  # Reduce from 500
```

---

## ðŸ”¹ 8. CWE Mapping Configuration

Both scripts support CWE mapping via config:

**In `model_config.yml` or `fusion_config.yml`:**

```yaml
cwe_mapping:
  high_confidence: "CWE-79"    # XSS (prob >= 0.9)
  medium_confidence: "CWE-89"  # SQL Injection (prob >= 0.7)
  low_confidence: "CWE-20"     # Input Validation (prob < 0.7)
```

Customize based on your domain knowledge!

---

## ðŸ”¹ 9. Batch Scripts (Windows PowerShell)

**`run_static_inference.ps1`:**
```powershell
python src/static/models/infer_xgboost_static.py `
    --model-path "models/static/xgb_static_v20231008_143022.joblib" `
    --input-path "datasets/features/test_features.csv" `
    --output-path "outputs/inference/static_results.jsonl" `
    --explain

Write-Host "âœ… Static inference complete!" -ForegroundColor Green
```

**`run_fusion_inference.ps1`:**
```powershell
python src/ml/fusion/infer_fusion_model.py `
    --model-path "models/fusion/xgb_fusion_v20231008_150022.joblib" `
    --static-results "outputs/inference/static_results.jsonl" `
    --codebert-results "outputs/inference/codebert_results.jsonl" `
    --graphcodebert-results "outputs/inference/graphcodebert_results.jsonl" `
    --output-path "outputs/inference/fusion_results.jsonl" `
    --explain

Write-Host "âœ… Fusion inference complete!" -ForegroundColor Green
```

---

## ðŸ”¹ 10. Model Version Management

Both scripts auto-detect companion files:

**Model Naming Convention:**
```
xgb_static_v20231008_143022.joblib      # Model
metadata_xgb_static_v20231008_143022.yaml  # Metadata
imputer_xgb_static_v20231008_143022.joblib  # Imputer
calibrated_xgb_static_v20231008_143022.joblib  # Calibrated model
```

Scripts automatically find matching files if they follow this pattern!

---

## âœ… Summary

**Static Inference:**
```bash
python src/static/models/infer_xgboost_static.py \
    --model-path <MODEL> --input-path <INPUT> --output-path <OUTPUT> --explain
```

**Fusion Inference:**
```bash
python src/ml/fusion/infer_fusion_model.py \
    --model-path <MODEL> \
    --static-results <STATIC_PREDS> \
    --codebert-results <CODEBERT_PREDS> \
    --graphcodebert-results <GRAPH_PREDS> \
    --output-path <OUTPUT> \
    --explain
```

Both scripts are production-ready, handle errors gracefully, and integrate seamlessly with your pipeline!

---

**Implementation By:** GitHub Copilot  
**Date:** October 8, 2025  
**Version:** 3.2.0 (Phase 3.2 - ML Enhancement)
